â­ 2. THE CORRECT LAYOUT OF THE GRID (engineering truth â†’ UI
truth)
ğŸ”µ TOP ROW: MODEL FAMILY & PARAMETERS
Your text says:
â€œAcross the top - parameters, with reasoning only on the biggest.
â€
This is exactly right but you need to show WHY visually.
UI idea:
Columns:
3B (no reasoning)
7B (no reasoning / shallow reasoning disabled)
13B (shallow reasoning ON)
70B (deep reasoning ON)
Frontier (full reasoning ON)
Each column auto-locks or unlocks reasoning depth.
This teaches:
â€œSmall models canâ€™t do deep reasoning.
â€
â€œReasoning mode isnâ€™t universal.
â€
Kids literally SEE the constraints, which is powerful.
ğŸŸ§ SECOND ROW: CONTEXT WINDOW
Your text:
â€œchoose smallest context that fits the input. Most queries â†’ max context.
Engineering truth:
Yes. 95% of tasks â†’ max context = best context.
UI idea:
A slider or a dropdown showing:
8k / 32k / 128k / 1M
Next to it: a gauge showing â€œyour input length vs max capacityâ€
But the genius UI detail:
When students increase context window, the cost indicator turns red.
This teaches:
memory is expensive
context â†‘ â†’ cost â†‘
context â†‘ â†’ latency â†‘
This alone teaches real engineering economics.
ğŸŸ¡ THIRD ROW: MAX SPEND PER QUERY (hard cap)
This is brilliant.
Kids need budget-based reasoning, not â€œmodel-based reasoning.
â€
UI mechanics:
A slider from $0.00 to $0.25 per query
As they move it, cells gray out because they are too expensive
The remaining cells light up green
The recommended model updates live
This is exactly how frontier teams choose models internally.
Teaching effect:
â€œModel choice always happens under compute + cost constraints.
This is the most important engineering intuition.
ğŸŸ© GRID CELLS: Each cell is a real model invocation
Cell contents:
progress bar (not text)
expected latency indicator
expected cost indicator
micro â€œreasoning depthâ€ summary
click to expand full answer
This lets students see:
â€œBig model reasoning took 4 seconds.
â€
â€œSmall model non-reasoning was instant but wrong.
â€
â€œ70B model got it right in 1.2 seconds.
â€
This is AI engineering embodied in UI.
ğŸŸ£ REALTIME STREAMING AS PROGRESS
Your idea is perfect: do NOT stream text.
Why?
Because students confuse:
more text = better reasoning
faster text = better model
Use:
circular progress spinners
latency meters
cost estimate meters
Make big models feel slower.
Make reasoning feel significantly slower.
This builds the physical intuition every good ML engineer has.





